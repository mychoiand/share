{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Intro to Grounding with Gemini in Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgrounding%2Fintro-grounding-gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub \n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/grounding/intro-grounding-gemini.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://goo.gle/4jeQyFS\">\n",
    "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in  Skills\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49e1e41cea0d"
   },
   "source": [
    "| Authors |\n",
    "| --- |\n",
    "| [Holt Skinner](https://github.com/holtskinner) |\n",
    "| [Kristopher Overholt](https://github.com/koverholt) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "**YouTube Video: Introduction to grounding with Gemini on Vertex AI**\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=Ph0g6dnsB4g&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
    "  <img src=\"https://img.youtube.com/vi/Ph0g6dnsB4g/maxresdefault.jpg\" alt=\"Introduction to grounding with Gemini on Vertex AI\" width=\"500\">\n",
    "</a>\n",
    "\n",
    "[Grounding in Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) lets you use generative text models to generate content grounded in your own documents and data. This capability lets the model access information at runtime that goes beyond its training data. By grounding model responses in Google Search results or data stores within [Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction), LLMs that are grounded in data can produce more accurate, up-to-date, and relevant responses.\n",
    "\n",
    "Grounding provides the following benefits:\n",
    "\n",
    "- Reduces model hallucinations (instances where the model generates content that isn't factual)\n",
    "- Anchors model responses to specific information, documents, and data sources\n",
    "- Enhances the trustworthiness, accuracy, and applicability of the generated content\n",
    "\n",
    "You can configure two different sources of grounding in Vertex AI:\n",
    "\n",
    "1. Google Search results for data that is publicly available and indexed.\n",
    "   - If you use this service in a production application, you will also need to [use a Google Search entry point](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/grounding-search-entry-points).\n",
    "2. [Data stores in Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest), which can include your own data in the form of website data, unstructured data, or structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to:\n",
    "\n",
    "- Generate LLM text and chat model responses grounded in Google Search results\n",
    "- Compare the results of ungrounded LLM responses with grounded LLM responses\n",
    "- Create and use a data store in Vertex AI Search to ground responses in custom documents and data\n",
    "- Generate LLM text and chat model responses grounded in Vertex AI Search results\n",
    "\n",
    "This tutorial uses the following Google Cloud AI services and resources:\n",
    "\n",
    "- Vertex AI\n",
    "- Vertex AI Search\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Configuring the LLM and prompt for various examples\n",
    "- Sending example prompts to generative text and chat models in Vertex AI\n",
    "- Setting up a data store in Vertex AI Search with your own data\n",
    "- Sending example prompts with various levels of grounding (no grounding, web grounding, data store grounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "1. Enable the [Vertex AI and Vertex AI Search APIs](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,discoveryengine.googleapis.com).\n",
    "1. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Install Google Gen AI SDK for Python\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:13:34.017466Z",
     "iopub.status.busy": "2026-02-26T14:13:34.016763Z",
     "iopub.status.idle": "2026-02-26T14:13:39.008134Z",
     "shell.execute_reply": "2026-02-26T14:13:39.005626Z",
     "shell.execute_reply.started": "2026-02-26T14:13:34.017410Z"
    },
    "id": "2b4ef9b72d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### Set Google Cloud project information and create client\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)\n",
    "\n",
    "You can also change the `LOCATION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:13:39.012132Z",
     "iopub.status.busy": "2026-02-26T14:13:39.011446Z",
     "iopub.status.idle": "2026-02-26T14:13:44.207838Z",
     "shell.execute_reply": "2026-02-26T14:13:44.206328Z",
     "shell.execute_reply.started": "2026-02-26T14:13:39.012068Z"
    },
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-01-6ba78d02384c\"\n",
    "LOCATION = \"global\"\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:14:03.093258Z",
     "iopub.status.busy": "2026-02-26T14:14:03.092176Z",
     "iopub.status.idle": "2026-02-26T14:14:03.106605Z",
     "shell.execute_reply": "2026-02-26T14:14:03.100610Z",
     "shell.execute_reply.started": "2026-02-26T14:14:03.093195Z"
    },
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown\n",
    "from IPython.display import display\n",
    "from google.genai.types import (\n",
    "    EnterpriseWebSearch,\n",
    "    GenerateContentConfig,\n",
    "    GenerateContentResponse,\n",
    "    GoogleMaps,\n",
    "    GoogleSearch,\n",
    "    LatLng,\n",
    "    Part,\n",
    "    Retrieval,\n",
    "    RetrievalConfig,\n",
    "    Tool,\n",
    "    ToolConfig,\n",
    "    VertexAISearch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e569c5d4a49"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:14:11.032176Z",
     "iopub.status.busy": "2026-02-26T14:14:11.031677Z",
     "iopub.status.idle": "2026-02-26T14:14:11.052875Z",
     "shell.execute_reply": "2026-02-26T14:14:11.051013Z",
     "shell.execute_reply.started": "2026-02-26T14:14:11.032124Z"
    },
    "id": "307f36dbd36c"
   },
   "outputs": [],
   "source": [
    "def print_grounding_data(response: GenerateContentResponse) -> None:\n",
    "    \"\"\"Prints Gemini response with grounding citations in Markdown format.\"\"\"\n",
    "    if not (response.candidates and response.candidates[0].grounding_metadata):\n",
    "        print(\"Response does not contain grounding metadata.\")\n",
    "        display(Markdown(response.text))\n",
    "        return\n",
    "\n",
    "    grounding_metadata = response.candidates[0].grounding_metadata\n",
    "    markdown_parts = []\n",
    "\n",
    "    # Citation indexes are in bytes\n",
    "    ENCODING = \"utf-8\"\n",
    "    text_bytes = response.text.encode(ENCODING)\n",
    "    last_byte_index = 0\n",
    "\n",
    "    if grounding_metadata.grounding_supports:\n",
    "        for support in grounding_metadata.grounding_supports:\n",
    "            markdown_parts.append(\n",
    "                text_bytes[last_byte_index : support.segment.end_index].decode(ENCODING)\n",
    "            )\n",
    "\n",
    "            # Generate and append citation footnotes (e.g., \"[1][2]\")\n",
    "            footnotes = \"\".join([f\"[{i + 1}]\" for i in support.grounding_chunk_indices])\n",
    "            markdown_parts.append(f\" {footnotes}\")\n",
    "\n",
    "            # Update index for the next segment\n",
    "            last_byte_index = support.segment.end_index\n",
    "\n",
    "    # Append any remaining text after the last citation\n",
    "    if last_byte_index < len(text_bytes):\n",
    "        markdown_parts.append(text_bytes[last_byte_index:].decode(ENCODING))\n",
    "\n",
    "    markdown_parts.append(\"\\n\\n----\\n## Grounding Sources\\n\")\n",
    "\n",
    "    if grounding_metadata.grounding_chunks:\n",
    "        # Build Grounding Sources Section\n",
    "        markdown_parts.append(\"### Grounding Chunks\\n\")\n",
    "        for i, chunk in enumerate(grounding_metadata.grounding_chunks, start=1):\n",
    "            context = chunk.web or chunk.retrieved_context or chunk.maps\n",
    "            if not context:\n",
    "                continue\n",
    "\n",
    "            uri = context.uri\n",
    "            title = context.title or \"Source\"\n",
    "\n",
    "            # Convert GCS URIs to public HTTPS URLs\n",
    "            if uri and uri.startswith(\"gs://\"):\n",
    "                uri = uri.replace(\n",
    "                    \"gs://\", \"https://storage.googleapis.com/\", 1\n",
    "                ).replace(\" \", \"%20\")\n",
    "\n",
    "            markdown_parts.append(f\"{i}. [{title}]({uri})\\n\")\n",
    "            if hasattr(context, \"place_id\") and context.place_id:\n",
    "                markdown_parts.append(f\"    - Place ID: `{context.place_id}`\\n\\n\")\n",
    "            if hasattr(context, \"text\") and context.text:\n",
    "                markdown_parts.append(f\"{context.text}\\n\\n\")\n",
    "\n",
    "    # Add Search/Retrieval Queries\n",
    "    if grounding_metadata.web_search_queries:\n",
    "        markdown_parts.append(\n",
    "            f\"\\n**Web Search Queries:** {grounding_metadata.web_search_queries}\\n\"\n",
    "        )\n",
    "        if grounding_metadata.search_entry_point:\n",
    "            markdown_parts.append(\n",
    "                f\"\\n**Search Entry Point:**\\n{grounding_metadata.search_entry_point.rendered_content}\\n\"\n",
    "            )\n",
    "    elif grounding_metadata.retrieval_queries:\n",
    "        markdown_parts.append(\n",
    "            f\"\\n**Retrieval Queries:** {grounding_metadata.retrieval_queries}\\n\"\n",
    "        )\n",
    "\n",
    "    display(Markdown(\"\".join(markdown_parts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55cf2dd17690"
   },
   "source": [
    "Initialize the Gemini model from Vertex AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:14:21.788395Z",
     "iopub.status.busy": "2026-02-26T14:14:21.787811Z",
     "iopub.status.idle": "2026-02-26T14:14:21.794894Z",
     "shell.execute_reply": "2026-02-26T14:14:21.792141Z",
     "shell.execute_reply.started": "2026-02-26T14:14:21.788348Z"
    },
    "id": "652a8969dd5a"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e336da7161af"
   },
   "source": [
    "## Example: Grounding with Google Search results\n",
    "\n",
    "In this example, you'll compare LLM responses with no grounding with responses that are grounded in the results of a Google Search. You'll ask a question about a the most recent solar eclipse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:14:31.178602Z",
     "iopub.status.busy": "2026-02-26T14:14:31.177038Z",
     "iopub.status.idle": "2026-02-26T14:14:31.189463Z",
     "shell.execute_reply": "2026-02-26T14:14:31.187602Z",
     "shell.execute_reply.started": "2026-02-26T14:14:31.178523Z"
    },
    "id": "6a28ca4abb52"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"What is today's date?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25955ce5d263"
   },
   "source": [
    "### Text generation without grounding\n",
    "\n",
    "Make a prediction request to the LLM with no grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:14:46.503469Z",
     "iopub.status.busy": "2026-02-26T14:14:46.502807Z",
     "iopub.status.idle": "2026-02-26T14:14:47.964502Z",
     "shell.execute_reply": "2026-02-26T14:14:47.963196Z",
     "shell.execute_reply.started": "2026-02-26T14:14:46.503420Z"
    },
    "id": "a2e348ff93e6"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Today is June 11, 2024."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d7cb7cceb99"
   },
   "source": [
    "### Text generation grounded in Google Search results\n",
    "\n",
    "You can add the `tools` keyword argument with a `Tool` including `GoogleSearch` to instruct Gemini to first perform a Google Search with the prompt, then construct an answer based on the web search results.\n",
    "\n",
    "The search queries and [Search Entry Point](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/grounding-search-entry-points) are available for each `Candidate` in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:15:05.312012Z",
     "iopub.status.busy": "2026-02-26T14:15:05.310225Z",
     "iopub.status.idle": "2026-02-26T14:15:06.120432Z",
     "shell.execute_reply": "2026-02-26T14:15:06.118862Z",
     "shell.execute_reply.started": "2026-02-26T14:15:05.311932Z"
    },
    "id": "1d9fb83b0ab9"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Today's date is Thursday, February 26, 2026.\n",
       "\n",
       "----\n",
       "## Grounding Sources\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"What is today's date?\"\n",
    "\n",
    "google_search_tool = Tool(google_search=GoogleSearch())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    "    config=GenerateContentConfig(tools=[google_search_tool]),\n",
    ")\n",
    "\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d3920bb2ac0"
   },
   "source": [
    "Note that the response without grounding only has limited information from the LLM about solar eclipses. Whereas the response that was grounded in web search results contains the most up to date information from web search results that are returned as part of the LLM with grounding request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59c98ab0f5fb"
   },
   "source": [
    "### Text generation with multimodal input grounded in Google Search results\n",
    "\n",
    "Gemini can also generate grounded responses with multimodal input. Let's try with this image of the Eiffel Tower.\n",
    "\n",
    "![Paris](https://storage.googleapis.com/github-repo/generative-ai/gemini/grounding/paris.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:15:26.186168Z",
     "iopub.status.busy": "2026-02-26T14:15:26.185177Z",
     "iopub.status.idle": "2026-02-26T14:15:31.962561Z",
     "shell.execute_reply": "2026-02-26T14:15:31.961268Z",
     "shell.execute_reply.started": "2026-02-26T14:15:26.186117Z"
    },
    "id": "5ebdda19afad"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current temperature in Paris, France, is 65째F (18째C), and it feels like 64째F (18째C). [1] The weather is partly sunny, with a humidity of around 54%. [1]\n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "### Grounding Chunks\n",
       "1. [Weather information for Paris, FR](https://www.google.com/search?q=weather+in+Paris,+FR)\n",
       "\n",
       "**Web Search Queries:** ['current temperature in Paris']\n",
       "\n",
       "**Search Entry Point:**\n",
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQERpKJf4KxDdit91Ap2A6lo8uY2BXd80nOklmlDuRK3CkevkaGUd88T-mwIxvCrlf__wXVYWWUqinirl9qyixi9R3lynttWRhzvwVk-CARa6pePEJ12ZIorEtJm0wAw96FOZO2D-oZoAl2JzSsvq_ZZskGOPvfWe66o6n9XE4TbeZiPUD-0HM7UN2iWNq8gRObol-Z0vGxvaH10BkBdgig=\">current temperature in Paris</a>\n",
       "  </div>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"What is the current temperature at this location?\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        Part.from_uri(\n",
    "            file_uri=\"gs://github-repo/generative-ai/gemini/grounding/paris.jpg\",\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "        PROMPT,\n",
    "    ],\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[google_search_tool],\n",
    "    ),\n",
    ")\n",
    "\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a29c93ef3f34"
   },
   "source": [
    "## Example: Grounding with Enterprise Web Search\n",
    "\n",
    "Grounding with Google Search uses Google Search to perform searches across the web. As part of this offering, Google Search might perform logging of customer queries (see [section 19.k of Google Cloud Service Specific Terms](https://cloud.google.com/terms/service-terms)). This often doesn't meet the compliance requirements of customers in highly regulated industries like Finance or Healthcare.\n",
    "\n",
    "Enterprise Web Search meets these requirements. When a customer uses Enterprise Web Search to ground on the web, this is done without logging of customer data and with full support for VPC SC and ML processing in-region. Enterprise Web Search Grounding is available in an US and EU multi-region.\n",
    "\n",
    "Request and response format for Enterprise Web Search Grounding are very similar to Grounding with Google Search.\n",
    "\n",
    "### Gemini model compatibility\n",
    "\n",
    "Enterprise Web Search is compatible with all Gemini 2.5 Flash models which support grounding. Gemini 2.5 Flash supports multimodal input (e.g. images, documents, videos). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:15:39.389357Z",
     "iopub.status.busy": "2026-02-26T14:15:39.388141Z",
     "iopub.status.idle": "2026-02-26T14:15:45.347756Z",
     "shell.execute_reply": "2026-02-26T14:15:45.346438Z",
     "shell.execute_reply.started": "2026-02-26T14:15:39.389295Z"
    },
    "id": "b2587492ab3f"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "England won the 2025 UEFA Women's European Championship, defeating Spain in the final. [1][2][3][4] The match took place on July 27, 2025, at St. Jakob-Park in Basel, Switzerland. [2] England secured their second UEFA Women's Euro title after a 1-1 draw with Spain was followed by a 3-1 victory in a penalty shootout. [2][3][4]\n",
       "\n",
       "It is important to note that the main UEFA European Championship for men's national teams (often referred to as the UEFA Euro) is typically held every four years and was not scheduled for 2025.\n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "### Grounding Chunks\n",
       "1. [olympics.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE3IBkF6o3Jzb_wj1MSPSq0t8-eOWWC8ZmKy5ebIpY_sC7AAJZNUTKGgQLuaQv-HcPz8-I3ZLEbxlWxx1RX5C4yxbRTd19dLx0Fh4t24NG-e9mJh4lXFzeYrB_v898IU9t1QVrKO7rMqwByl_aWXKnjylxu4ZlyuIB4J6RUstNjrssAiTIhmg4oOUnD_AMBqU7iWhTJE1ukX8-o2g==)\n",
       "2. [wikipedia.org](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFktgQeAUdESGF6GH-kMJwJH1ymWunduHU5cpp3um7RLuLGjR7kMGaEmjlvDn9g5q3hkZ9rZIztjthuse25FW0c_61mtsKC2GyTUwaBQHCIkJd6m9bzidG25FbzYBXiB2OzArHjsGFTzuSn8DAyXRikNilpx7uK)\n",
       "3. [uefa.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEN0oQWCZBqtvSsoSApfPvnNgfmpM2K2skdy7sqC9s3hzghD8V1Kv-KUlu5-Ou5O_UrX0ZsUBZWMczWx7CLcg27ukekrhqoTmuIkIjPwEj1FMwVCzBU3xp6GQ6oQtiH6yg77qJlcP2-JMcEOVjtVp1OL285vhHOIwXLlnXfiupBfDclEH1GKc1DxdEaByF2YY13yyr1fxsK_cqQVtR_QEI-ENACD8Eck1A5h1dHwge3lfr15Iw=)\n",
       "4. [wikipedia.org](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGDXTItDfnJ4Ey4bcWiLsuqg_qcORFyTmu6WT99G3Ki6AfNf_gNm0nm8cvabIPKvrFXJI8NXCw21vin1RP8SuBI-H1X8gr0qaCw8bdfas5CU1qBXxtwWc1MD7uWcz0QW_CJn-yOPYIyUnjoJJVcmQoV)\n",
       "\n",
       "**Web Search Queries:** ['who won 2025 UEFA European Championship']\n",
       "\n",
       "**Search Entry Point:**\n",
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFNIQwZr1J4Jw8Yn-X70FN_lUsj5ZjlqsVcC9oEGX-lXMrtkbSE6JGgFFqs9fdrX_-ST-dOhB6mAWX20B1cUUAFvIHeyWqxo1WEpEWk35oXIc1vgjgiDS93unOPfUT1HeB2k4XOFoouYolrLTs503rrrRgJGS5-ImBby_5Y7tK-Xak-S_3AcNkpa_qlDAppasB7K08DAZnX9lk-whzeM-zePzAIQsTxg5jF\">who won 2025 UEFA European Championship</a>\n",
       "  </div>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"Who won the 2025 UEFA European Championship?\"\n",
    "\n",
    "enterprise_web_search_tool = Tool(enterprise_web_search=EnterpriseWebSearch())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    "    config=GenerateContentConfig(tools=[enterprise_web_search_tool]),\n",
    ")\n",
    "\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6708e03a1d7b"
   },
   "source": [
    "## Example: Grounding with Google Maps\n",
    "\n",
    "You can also use Google Maps data for grounding with Gemini. See the [documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T14:15:48.555136Z",
     "iopub.status.busy": "2026-02-26T14:15:48.554501Z",
     "iopub.status.idle": "2026-02-26T14:15:58.141600Z",
     "shell.execute_reply": "2026-02-26T14:15:58.139636Z",
     "shell.execute_reply.started": "2026-02-26T14:15:48.555089Z"
    },
    "id": "ebfa54b6b14e"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Las Vegas offers a diverse and highly-rated selection of vegetarian dining options, ranging from upscale vegan experiences to casual eateries with excellent plant-based choices.\n",
       "\n",
       "For a refined vegan dining experience, consider **Crossroads Kitchen Las Vegas**, an upscale plant-based restaurant featuring signature dishes by acclaimed Chef Tal Ronnen. It boasts a rating of 4.6 stars. [1] Another popular all-vegan choice is **The Modern Vegan**, known for its extensive menu of creative plates for breakfast, lunch, and brunch, including comfort food like vegan burgers and chicken-waffles. [2] **Earthly Plant Based Eatery** offers a relaxed atmosphere with plant-based meals that include a Southern twist, such as macaroni and cheese and waffles, and holds a 4.8-star rating. [3]\n",
       "\n",
       "If you're in the mood for vegan Mexican fare, **Tacotarian** is a charming spot serving classic dishes like tacos and quesadillas in a bohemian setting, rated 4.8 stars. [4] For vegan Italian, **Tarantino's Vegan** is highly recommended for its wood-fired pizzas, pastas, and Italian classics, also offering gluten-free options. [5]\n",
       "\n",
       "Asian cuisine also has strong vegetarian representation. **Saffron Lounge** provides upscale vegan Thai-accented dishes, including noodles and cocktails, with a 4.4-star rating. [6] **Chef Kenny's Vegan Dim Sum** specializes in plant-based Asian staples like curries, noodles, and sushi in a casual setting and has a 4.8-star rating. [7] **Daikon Vegan Sushi - Lake Mead** offers plant-based Japanese entrees, appetizers, and sushi in a relaxed, counter-service environment, with an impressive 4.9-star rating. [8] For a broader Asian experience, **8 East** serves eclectic Asian dishes and has vegetarian options available. [9]\n",
       "\n",
       "Several other restaurants offer excellent vegetarian options alongside their regular menus. **Marigold Fine Indian Cuisine** is a bustling spot for Indian classics and explicitly serves vegetarian food, with an outstanding 4.9-star rating. [10] **True Food Kitchen** is an eco-chic chain known for its health-conscious fare, including many vegan options, and is rated 4.5 stars. [11] Similarly, **Truth & Tonic** at The Venetian Resort provides vegan and health-conscious cuisine in an upmarket cafe setting. [12]\n",
       "\n",
       "For casual meals, **Garden Grill** is a plant-based stop dishing up sandwiches, tacos, and wraps, holding a 4.8-star rating. [13] **Flower Child** offers healthy American meals with vegan and gluten-free options in a laid-back setting. [14] **Nacho Daddy - Downtown** offers a variety of nacho plates and Mexican classics, and explicitly serves vegetarian food. [15]\n",
       "\n",
       "Even some traditional restaurants cater well to vegetarians. **Casa Di Amore**, a homey Italian-American spot, serves vegetarian food and has live music. [16] **Black & Blue Diner** is a familiar brunch spot offering classic dishes, along with vegan options. [17] Additionally, places like **Daily Dose Cafe** [18], **Lucky 3 Food Co** [19], **La Mona Rosa** [20], **Broken Yolk Cafe** [21], and **Parlour neighborhood social eatery** [22] all serve vegetarian food, often with breakfast, brunch, or American comfort food themes.\n",
       "\n",
       "For those looking for a unique dining experience with vegetarian choices, **Top of the World** provides New American cuisine with panoramic views from the 106th floor of the Stratosphere Tower and also serves vegetarian food. [23]\n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "### Grounding Chunks\n",
       "1. [Crossroads Kitchen Las Vegas](https://maps.google.com/?cid=706150781634449458)\n",
       "    - Place ID: `places/ChIJ01PwO_HFyIARMpAvAWXAzAk`\n",
       "\n",
       "2. [The Modern Vegan](https://maps.google.com/?cid=14221527166959319345)\n",
       "    - Place ID: `places/ChIJAQBQ8qzFyIARMXktBpwDXcU`\n",
       "\n",
       "3. [Earthly Plant Based Eatery](https://maps.google.com/?cid=368520640861788812)\n",
       "    - Place ID: `places/ChIJGdVeD4HDyIARjFr3ApI_HQU`\n",
       "\n",
       "4. [Tacotarian](https://maps.google.com/?cid=17107788727078046360)\n",
       "    - Place ID: `places/ChIJE7jV_vDDyIARmErr0TQTa-0`\n",
       "\n",
       "5. [Tarantino's Vegan](https://maps.google.com/?cid=14214067733621445073)\n",
       "    - Place ID: `places/ChIJdQRUoJ7JyIAR0RHZW0uDQsU`\n",
       "\n",
       "6. [Saffron Lounge](https://maps.google.com/?cid=8903658376024737482)\n",
       "    - Place ID: `places/ChIJ3WKhG_7HyIARysZikB4mkHs`\n",
       "\n",
       "7. [Chef Kenny's Vegan Dim Sum](https://maps.google.com/?cid=9478828023746152783)\n",
       "    - Place ID: `places/ChIJKcB381HHyIART0lo2t2Pi4M`\n",
       "\n",
       "8. [Daikon Vegan Sushi - Lake Mead](https://maps.google.com/?cid=3157048547188399183)\n",
       "    - Place ID: `places/ChIJXWYxWrzByIART9zTSe0W0Cs`\n",
       "\n",
       "9. [8 East](https://maps.google.com/?cid=8803243885999280532)\n",
       "    - Place ID: `places/ChIJWTkzgUnDyIARlNEdOKxnK3o`\n",
       "\n",
       "10. [Marigold Fine Indian Cuisine](https://maps.google.com/?cid=11229744775408114305)\n",
       "    - Place ID: `places/ChIJj3XAJ9PHyIARgdp_IGAR2Js`\n",
       "\n",
       "11. [True Food Kitchen](https://maps.google.com/?cid=14584975186362523728)\n",
       "    - Place ID: `places/ChIJixtBQDzEyIARUGAGUag9aMo`\n",
       "\n",
       "12. [Truth & Tonic](https://maps.google.com/?cid=13711598273974243803)\n",
       "    - Place ID: `places/ChIJsd0CktHFyIAR2xEYp_thSb4`\n",
       "\n",
       "13. [Garden Grill](https://maps.google.com/?cid=6429160112674470465)\n",
       "    - Place ID: `places/ChIJGXRUtoe_yIARQXoSMA_3OFk`\n",
       "\n",
       "14. [Flower Child](https://maps.google.com/?cid=10278077965450937997)\n",
       "    - Place ID: `places/ChIJ4bJCpoO_yIARjQZ5OHQRo44`\n",
       "\n",
       "15. [Nacho Daddy - Downtown](https://maps.google.com/?cid=14565512590049271497)\n",
       "    - Place ID: `places/ChIJtY8W_J_DyIARyd5dfYcYI8o`\n",
       "\n",
       "16. [Casa Di Amore](https://maps.google.com/?cid=11609373723531747896)\n",
       "    - Place ID: `places/ChIJ2368TTnFyIAROCLdd-THHKE`\n",
       "\n",
       "17. [Black & Blue Diner](https://maps.google.com/?cid=11720482111110820243)\n",
       "    - Place ID: `places/ChIJkYVjCQrByIARk7EU3WGEp6I`\n",
       "\n",
       "18. [Daily Dose Cafe](https://maps.google.com/?cid=4542165734446908440)\n",
       "    - Place ID: `places/ChIJe9-Tck3DyIARGMSoiKsDCT8`\n",
       "\n",
       "19. [Lucky 3 Food Co](https://maps.google.com/?cid=12894063840645433730)\n",
       "    - Place ID: `places/ChIJcxpLVp3DyIARgknhVL_q8LI`\n",
       "\n",
       "20. [La Mona Rosa](https://maps.google.com/?cid=2800898396128474280)\n",
       "    - Place ID: `places/ChIJ5bm6WrPDyIARqPQyYUDK3iY`\n",
       "\n",
       "21. [Broken Yolk Cafe](https://maps.google.com/?cid=17980795777016490413)\n",
       "    - Place ID: `places/ChIJ1UtJaOzDyIARrWnpK36eiPk`\n",
       "\n",
       "22. [Parlour neighborhood social eatery](https://maps.google.com/?cid=6026057012040619089)\n",
       "    - Place ID: `places/ChIJmVCT1RvDyIARUdTuzuzaoFM`\n",
       "\n",
       "23. [Top of the World](https://maps.google.com/?cid=11184959033055112326)\n",
       "    - Place ID: `places/ChIJEbZyKojDyIARhuyL6Pr0OJs`\n",
       "\n",
       "24. [Durvo](https://maps.google.com/?cid=14023613668218861106)\n",
       "    - Place ID: `places/ChIJMQ4YcQDHyIARMnZ_uVTincI`\n",
       "\n",
       "25. [Smash Me Baby](https://maps.google.com/?cid=3344397384177950103)\n",
       "    - Place ID: `places/ChIJmYkHvXHDyIARlx2sl7OvaS4`\n",
       "\n",
       "26. [Prone to Plants](https://maps.google.com/?cid=15951902673537145368)\n",
       "    - Place ID: `places/ChIJQxhZxP_FyIARGBrJ-_aKYN0`\n",
       "\n",
       "27. [Thai Street Cafe](https://maps.google.com/?cid=17287948997942747359)\n",
       "    - Place ID: `places/ChIJ8-D73BHEyIAR36BypQQi6-8`\n",
       "\n",
       "28. [VeggiEAT](https://maps.google.com/?cid=6381364162188728590)\n",
       "    - Place ID: `places/ChIJcaMisfjQyIARDtmqReUoj1g`\n",
       "\n",
       "29. [Main St. Provisions](https://maps.google.com/?cid=10985359209889680923)\n",
       "    - Place ID: `places/ChIJdRZiD5jDyIARG06Km__Vc5g`\n",
       "\n",
       "\n",
       "**Retrieval Queries:** ['best vegetarian restaurants Las Vegas', 'highly-rated vegan restaurants Las Vegas']\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "google_maps_tool = Tool(google_maps=GoogleMaps())\n",
    "\n",
    "PROMPT = \"Recommend some good vegetarian food in Las Vegas.\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        PROMPT,\n",
    "    ],\n",
    "    config=GenerateContentConfig(\n",
    "        system_instruction=\"You are a helpful assistant that provides information about locations. You have access to map data and can answer questions about distances, directions, and points of interest.\",\n",
    "        tools=[google_maps_tool],\n",
    "        # Optional: Set Latitude and Longitude for the Google Maps tool\n",
    "        tool_config=ToolConfig(\n",
    "            retrieval_config=RetrievalConfig(\n",
    "                lat_lng=LatLng(latitude=36.1699, longitude=-115.1398)\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77f0800f8762"
   },
   "source": [
    "## Example: Grounding with custom documents and data\n",
    "\n",
    "In this example, you'll compare LLM responses with no grounding with responses that are grounded in the [results of a search app in Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest).\n",
    "\n",
    "The data store will contain internal documents from a fictional bank, Cymbal Bank. These documents aren't available on the public internet, so the Gemini model won't have any information about them by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b308548c68b"
   },
   "source": [
    "### Creating a data store in Vertex AI Search\n",
    "\n",
    "In this example, you'll use a Google Cloud Storage bucket with a few sample internal documents for our bank. There's some docs about booking business travel, strategic plan for this Fiscal Year and HR docs describing the different jobs available in the company.\n",
    "\n",
    "Follow the tutorial steps in the Vertex AI Search documentation to:\n",
    "\n",
    "1. [Create a data store with unstructured data](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#unstructured-data) that loads in documents from the GCS folder `gs://cloud-samples-data/gen-app-builder/search/cymbal-bank-employee`.\n",
    "2. [Create a search app](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app) that is attached to that data store. You should also enable the **Enterprise edition features** so that you can search indexed records within the data store.\n",
    "\n",
    "**Note:** The data store must be in the same project that you are using for Gemini.\n",
    "\n",
    "You can also follow this notebook to do it with code. [Create a Vertex AI Search Datastore and App](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/create_datastore_and_search.ipynb)\n",
    "\n",
    "Once you've created a data store, obtain the App ID and input it below.\n",
    "\n",
    "Note: You will need to wait for data ingestion to finish before using a data store with grounding. For more information, see [create a data store](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T15:38:15.880593Z",
     "iopub.status.busy": "2026-02-26T15:38:15.879918Z",
     "iopub.status.idle": "2026-02-26T15:38:15.892420Z",
     "shell.execute_reply": "2026-02-26T15:38:15.890142Z",
     "shell.execute_reply.started": "2026-02-26T15:38:15.880533Z"
    },
    "id": "fcd767476241"
   },
   "outputs": [],
   "source": [
    "VERTEX_AI_SEARCH_PROJECT_ID = PROJECT_ID  # @param {type: \"string\"}\n",
    "VERTEX_AI_SEARCH_REGION = \"global\"  # @param {type: \"string\"}\n",
    "# Replace this with your App (Engine) ID from Vertex AI Search\n",
    "#VERTEX_AI_SEARCH_APP_ID = \"cymbal-bank-onboarding\"  # @param {type: \"string\"}\n",
    "VERTEX_AI_SEARCH_APP_ID = \"cymbal-bank-app\"\n",
    "\n",
    "VERTEX_AI_SEARCH_ENGINE_NAME = f\"projects/{VERTEX_AI_SEARCH_PROJECT_ID}/locations/{VERTEX_AI_SEARCH_REGION}/collections/default_collection/engines/{VERTEX_AI_SEARCH_APP_ID}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccc156676e0a"
   },
   "source": [
    "Now you can ask a question about the company culture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T15:38:30.443891Z",
     "iopub.status.busy": "2026-02-26T15:38:30.442634Z",
     "iopub.status.idle": "2026-02-26T15:38:30.454314Z",
     "shell.execute_reply": "2026-02-26T15:38:30.451573Z",
     "shell.execute_reply.started": "2026-02-26T15:38:30.443819Z"
    },
    "id": "9c1e1b1743bd"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"What is the company culture like?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f365681544bb"
   },
   "source": [
    "### Text generation without grounding\n",
    "\n",
    "Make a prediction request to the LLM with no grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T15:38:32.103267Z",
     "iopub.status.busy": "2026-02-26T15:38:32.102419Z",
     "iopub.status.idle": "2026-02-26T15:38:52.024266Z",
     "shell.execute_reply": "2026-02-26T15:38:52.022882Z",
     "shell.execute_reply.started": "2026-02-26T15:38:32.103225Z"
    },
    "id": "299818ae71e9"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "That's a fantastic question, and arguably one of the most important factors when considering a job or trying to understand an organization!\n",
       "\n",
       "As an AI, I don't *have* a company culture in the human sense. I don't work in an office, have colleagues, or participate in team-building exercises. My \"culture\" is defined by my programming, the data I'm trained on, and the ethical guidelines I'm designed to follow (e.g., being helpful, harmless, and honest).\n",
       "\n",
       "However, I can tell you what \"company culture\" generally entails for a human organization and give you an example of what a positive one often looks like.\n",
       "\n",
       "**What is Company Culture?**\n",
       "\n",
       "Company culture is the personality of an organization. It's the shared values, beliefs, attitudes, standards, and practices that characterize an organization and its employees. It influences how people interact with each other, how decisions are made, and how work gets done.\n",
       "\n",
       "Key aspects that define a company's culture often include:\n",
       "\n",
       "1.  **Values & Vision:** What does the company stand for? What's its mission and purpose beyond just making money? Are ethics, integrity, and social responsibility central?\n",
       "2.  **Communication & Collaboration:** Is communication open and transparent, or siloed and guarded? Is teamwork highly valued, or is it more individualistic and competitive?\n",
       "3.  **Work Environment & Pace:** Is it fast-paced and high-pressure, or more relaxed and methodical? Is it formal or informal? Is innovation encouraged or is there resistance to change?\n",
       "4.  **Leadership & Management Style:** Are leaders empowering and supportive, or more authoritarian and micromanaging? Is feedback regular and constructive?\n",
       "5.  **Growth & Development:** Are there opportunities for learning, training, and career advancement? Is mentorship available?\n",
       "6.  **Work-Life Balance:** Does the company support employees in maintaining a healthy balance between their professional and personal lives? Are long hours expected, or is flexibility offered?\n",
       "7.  **Diversity, Equity & Inclusion (DEI):** Is there a commitment to a diverse workforce and an inclusive environment where all employees feel valued and belong?\n",
       "8.  **Recognition & Rewards:** How are employees recognized and rewarded for their contributions? Is appreciation a regular part of the culture?\n",
       "9.  **Social & Community:** Are there team events, social gatherings, or community involvement initiatives?\n",
       "\n",
       "**Example of a Positive and Effective Company Culture (Hypothetical):**\n",
       "\n",
       "If I were to describe a company culture that fosters high performance and employee satisfaction, it would likely include:\n",
       "\n",
       "*   **Open and Transparent Communication:** Information flows freely, feedback is encouraged at all levels, and leaders are accessible.\n",
       "*   **Collaborative and Supportive:** Teams work together, help each other, and celebrate collective successes. A \"we're in this together\" mentality.\n",
       "*   **Innovative and Adaptable:** Employees are encouraged to experiment, learn from mistakes, and propose new ideas without fear of failure.\n",
       "*   **Empowering and Trusting:** Managers trust employees to do their best work and give them autonomy over their tasks, focusing on results rather than micromanaging processes.\n",
       "*   **Strong Focus on Growth:** There are clear pathways for career development, regular learning opportunities, and a culture of continuous improvement.\n",
       "*   **Respect for Work-Life Balance:** The company understands that employees have lives outside of work and actively promotes policies and practices (like flexible hours or remote work options) that support well-being.\n",
       "*   **Inclusive and Diverse:** Every voice is heard, differences are celebrated, and everyone feels a sense of belonging.\n",
       "*   **Recognition and Appreciation:** Achievements are acknowledged, and hard work is regularly praised, making employees feel valued.\n",
       "*   **Mission-Driven:** Employees understand and believe in the company's purpose, feeling a sense of meaning in their work.\n",
       "\n",
       "To truly understand a company's culture, you'd need to look at their website, read employee reviews (e.g., Glassdoor, LinkedIn), ask questions during interviews, and ideally, observe the environment firsthand."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "073f2ec42ff6"
   },
   "source": [
    "### Text generation grounded in Vertex AI Search results\n",
    "\n",
    "Now we can add the `tools` keyword arg with a grounding tool of `grounding.VertexAISearch()` to instruct the LLM to first perform a search within your search app, then construct an answer based on the relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T15:39:12.935584Z",
     "iopub.status.busy": "2026-02-26T15:39:12.934889Z",
     "iopub.status.idle": "2026-02-26T15:39:14.459309Z",
     "shell.execute_reply": "2026-02-26T15:39:14.457960Z",
     "shell.execute_reply.started": "2026-02-26T15:39:12.935525Z"
    },
    "id": "d4c5d53a37b4"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please specify which company you are interested in so I can tell you about its company culture.\n",
       "\n",
       "----\n",
       "## Grounding Sources\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vertex_ai_search_tool = Tool(\n",
    "    retrieval=Retrieval(\n",
    "        vertex_ai_search=VertexAISearch(engine=VERTEX_AI_SEARCH_ENGINE_NAME)\n",
    "    )\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What is the company culture like?\",\n",
    "    config=GenerateContentConfig(tools=[vertex_ai_search_tool]),\n",
    ")\n",
    "\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3f985c704cd"
   },
   "source": [
    "Note that the response without grounding doesn't have any context about what company we are asking about. Whereas the response that was grounded in Vertex AI Search results contains information from the documents provided, along with citations of the information.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>截 Important notes:</b><br>\n",
    "<br>\n",
    "<b>If you get an error when running the previous cell:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;In order for this sample notebook to work with data store in Vertex AI Search,<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;you'll need to create a <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_data_store\">data store</a> <b>and</b> a <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app\">search app</a> associated with it in Vertex AI Search.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;If you only create a data store, the previous request will return errors when making queries against the data store.\n",
    "<br><br>\n",
    "<b>If you get an empty response when running the previous cell:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;You will need to wait for data ingestion to finish before using a data store with grounding.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;For more information, see <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es\">create a data store</a>.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54562717e2a4"
   },
   "source": [
    "## Example: Grounded chat responses\n",
    "\n",
    "You can also use grounding when using chat conversations in Vertex AI. In this example, you'll compare LLM responses with no grounding with responses that are grounded in the results of a Google Search and a data store in Vertex AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T15:39:39.599394Z",
     "iopub.status.busy": "2026-02-26T15:39:39.598816Z",
     "iopub.status.idle": "2026-02-26T15:39:39.605527Z",
     "shell.execute_reply": "2026-02-26T15:39:39.603744Z",
     "shell.execute_reply.started": "2026-02-26T15:39:39.599351Z"
    },
    "id": "490cf1ed3399"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"What are managed datasets in Vertex AI?\"\n",
    "PROMPT_FOLLOWUP = \"What types of data can I use?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b59783e4f1ce"
   },
   "source": [
    "### Chat session grounded in Google Search results\n",
    "\n",
    "Now you can add the `tools` keyword arg with a Tool of `GoogleSearch` to instruct the chat model to first perform a Google Search with the prompt, then construct an answer based on the web search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T15:39:41.094322Z",
     "iopub.status.busy": "2026-02-26T15:39:41.093111Z",
     "iopub.status.idle": "2026-02-26T15:39:52.423879Z",
     "shell.execute_reply": "2026-02-26T15:39:52.420253Z",
     "shell.execute_reply.started": "2026-02-26T15:39:41.094277Z"
    },
    "id": "58edb2bd860f"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Prompt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> What are managed datasets in Vertex AI?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Managed datasets in Vertex AI are a core component for organizing and preparing data for machine learning (ML) workloads within the Google Cloud ecosystem. They provide a centralized and streamlined way to manage your data throughout the ML lifecycle, from initial ingestion to model training and evaluation. [1][2]\n",
       "\n",
       "Key aspects and benefits of managed datasets include:\n",
       "*   **Centralized Management** They offer a single location to manage your datasets, simplifying organization and access. [1][2]\n",
       "*   **Data Types Supported** Vertex AI supports managed datasets for various data types, including images, tabular data, text, and video. [3]\n",
       "*   **Annotation and Labeling** You can easily create labels, multiple annotation sets, and even establish tasks for human labeling, which is crucial for supervised learning models. [1][2]\n",
       "*   **Lineage Tracking** Managed datasets help track the lineage of your data, linking it to the models trained, which aids in governance and iterative development. [1][2]\n",
       "*   **Model Performance Comparison** They enable you to compare the performance of different AI models by training them on the same dataset. [1][2]\n",
       "*   **Data Statistics and Visualization** Managed datasets can generate data statistics and visualizations, offering insights into your data. [1][2]\n",
       "*   **Automated Data Splitting** Vertex AI can automatically split your datasets into training, validation, and testing sets, a standard practice in ML. [1][2]\n",
       "*   **Integration with AutoML** Managed datasets are essential for training AutoML models and Gemini models. While not strictly required for custom models, they significantly reduce workload within the Vertex AI ecosystem. [1][4]\n",
       "*   **Data Referencing vs. Management** For some data types, like tabular data sourced from a CSV file in a Google Cloud Storage (GCS) bucket, a managed dataset might primarily act as a reference to the data, meaning no duplication occurs. [5][6] However, for other data types, such as text datasets, Vertex AI might manage the data itself in a Google-generated GCS bucket. [6]\n",
       "*   **Flexibility in Data Source** You can create managed datasets by importing data from various sources, including BigQuery tables or CSV files in Cloud Storage. [5]\n",
       "\n",
       "In essence, managed datasets streamline the data preparation and management phases, making it easier to build, train, and deploy ML models within Vertex AI.\n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "### Grounding Chunks\n",
       "1. [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFNco7JKS5Swsf2vvhUR1pkL9s73X5fQBPsTsFZlHOSvXkV8Ma-_fiVGbupNRTsY7HODXgdvUQe0OyQa2UqxG5CLBE-rWoPoxHLkDQceMMG03r9XpIWb62oOJLbkx9CA-lM7dSc8LwFqFBZuHKr0N7-T7B4PslhgbTCP3BlYIbQoKk_aNkg07BJIBep9epsqvylLct_eHggr9A9NLk82gsu-NG_yBQSmqeC4g==)\n",
       "2. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGUppzVSRvUXblrGZQTYjG1OzxaVT73ik90XjHLvH4Clmbm8Je91TxWWNhcgmZ6fUzAjOnwRCaoEIP4YUXaIfnjzkCAmtWNdR6ZsFqOQbclx20BXtRdv471DmHjE9kOz9CJPySNqOeOOqUqr9FTTxgZUzRpgE78DO84WlISCjsCCQTZaXTuMkw=)\n",
       "3. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF2lQh7Cdkg_9RM3s7cvf74tPtWKoVoahY_5D_Mq0fI5qYNBxwTJsP1vF0RmsmKbHzISNoHuOFADNpSnJHpyNhPa0lpYymIPitV1dYl3EzEqSGPMbsiyu-T_GacoRclLTsZcQyjKy4IoOQotKYFJp0dVxsmh5H-jxqSR7cImPgyD61u9dOZgik_-xHSoxtSMSeUzdbzFqYfuKyiIYyME7NSXZM=)\n",
       "4. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGY7Lp6TQ_Fl2_USmuz20jQ94rR40ApYwonAlIjjEeiWpM-sQ0JVhVlZqOFYds_6RCre2qn9xG4wD6AxVjdkB_Oz08t0f_keqtzaYBnqpZSkmLPGGo_RJ4hpHesw5owYTiUaRE9mYCqqmtR7U89z4nDkuRz4p89XSeo)\n",
       "5. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGY4qs_-ddAV1q9iUlZyGRRxXziUZrX-0ZPjOo_BQelf67hGy2iRzQgUn6pJEDzmlvzdarRM4bCeqzjoQy5hiTV_4pz9uPRIcSt3p_fvwXvQszrN5OFv8C-tGH-OBzfFNUluIonwjE7TETHZp7-P6_O-xQtavY3c7XIgch9rhp4MPtrS9cLKWmP-Q==)\n",
       "6. [leftasexercise.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF9yA_nnP1SxRw9XsBph9xvGX5ab1S_zelPGclMFcyPoESyoBX7cdQl89bMH2MAyz-aBMPEBHOTMYRTIn2NgXukBAcJXZ5uqrr4Tb_erwZpNjpFAadr6IEmmhXhS0mDOE3dBQyG7_hIbqJ4OLutmYPbMIPz9OOS-YkadyAc8j_OOeicN41gvI62Mabek87KVV2e)\n",
       "\n",
       "**Web Search Queries:** ['Vertex AI managed datasets', 'What are managed datasets in Google Cloud Vertex AI']\n",
       "\n",
       "**Search Entry Point:**\n",
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHsLXhTfBCNkA4wb7gefHeh4lSNIuX8-7fRUBk_U_IFNPrQb0Xo-2qZGrlJYi2WxAcv-kqFynRt2s5CG-rXkrOQsJFUwbcpWfvY2Fx0JiKSVKzhqDvDcWYW_7g86ytYXGdFx1hFnv26FY4TLsz9dJTDKflk14z6dnRny-vyn84ZQMG7XJYjJRdlAkkzIJzLn4Imv-0vBhoaTrroivHSwBh60nFNCJw0Xolu4ycYzYxdH9U57XW_K68=\">What are managed datasets in Google Cloud Vertex AI</a>\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGcSdfxADhGfrkaaa9uqHDzVPerJAFUs_e7gPTljh6m6YKtLHeTzTmS0GcrDRaxZyAze28uw-ZWyEfiwlYdUIJ6ni0Gl_mSPWuQmG1l_R3bKJ8sig5mgmQ1ZFgd4Ha6EUVr6vjNV13i1lpn7DiZ5R4eVNb47oC7Rmk7FqF-eLZXTILaVTSI_otqPpmSR9WrmdLlDvdjsfTi0HekAzn1\">Vertex AI managed datasets</a>\n",
       "  </div>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Follow-up Prompt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> What types of data can I use?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Vertex AI managed datasets support four primary types of data, allowing for a wide range of machine learning tasks:\n",
       "\n",
       "*   **Image data:** Used for tasks such as image classification (identifying items within an image), object detection (locating specific items in an image), and image segmentation (assigning labels to pixel-level regions). Supported image formats include PNG, JPEG, GIF, BMP, and ICO. [1][2]\n",
       "*   **Tabular data:** Ideal for regression (predicting numerical values), classification (predicting categories), and forecasting (predicting the likelihood of events). Tabular data can be sourced from CSV files in Cloud Storage or directly from BigQuery tables. [3][1][4] Vertex AI uses the RFC 4180 CSV format, and supports compound data types like Struct and Array for BigQuery sources when performing classification or regression. [3]\n",
       "*   **Text data:** Enables tasks like classification (assigning labels to an entire document), entity extraction (identifying custom text entities), and sentiment analysis (determining the overall sentiment). [1]\n",
       "*   **Video data:** Primarily used for classification tasks, where videos are labeled based on training data. [1][2] Supported video formats include .MOV, .MPEG4, .MP4, and .AVI, with MPEG4 or .MP4 being recommended for browser compatibility. [2]\n",
       "\n",
       "For all these data types, Vertex AI passes the data to your training application in specific formats, such as JSON Lines for image, text, and video datasets, or CSV/BigQuery URI for tabular datasets. [5]\n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "### Grounding Chunks\n",
       "1. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGPQO9AfGKVXKOkUthtE9tyfSC1LfXibYHAuE_ChBm5Q_nVAAXoZchRzoONBgEGG9cUUWtc68-IxgvXdNS_X0HyJvsbAko3ZLOhW_nd6f1mLZpVTpawDK26x41guvfJelGGSzue4cb5ntxRqcV3oEm6XRJnV8GIkbOcAm5UDbQs2hh6kq_2id7eLjD8VPxmwfOw6jVzNOGPgmtGoUfgkE-yWLc=)\n",
       "2. [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGclTzf2uGsVYsjcaA99OFWHFG7hLA-vm1_2LTUsPxTDfJYX8lkBbcGfuCMV2oOYK0UxdBw8J08mp63fZtwBoJqwi004nkUJEXOo3f018dlUEDAAzfuUNzymJsp5d7LAYz0uAktR6GJE5uq7VL2ORYyO8BbRsM82McQzXOjLaB9o17YULUg3OQ_4ypnLhch-4czBB1Cp7eqjaAW3i68BmOlT8W1R2IlEOeqeg==)\n",
       "3. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEuJwjm4hTFjj_RbiI_4wRDqCOw7SgeGBaq8CoODBFNAndOAbHHtJYPe6PxPRdm0r-NPr-PdcpCj89ICptrn6zZiFCJnzAMnNfYekVxgEOY0Ruo_xOMMHD60x2PoYqKh08d0cgbhMwFC5oovRrs8U_4U9MrmbKZEfGa5uTdxxvlN6GxOw==)\n",
       "4. [youtube.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGHua5RThYsNXtAGSM0dtIrNvAGGN4Ur17Q9CpeQRMF5gGUa2BHrDEwhxYH3yFCgtopsMGX1jrGNyMrYwNopw0dxVuvtLXxvLgD2vp0Ph8hzJxLkAOGM2j6sdwEJgklLvSXJcaL6uc=)\n",
       "5. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGPJX0Rb-hKufTq-huS0IBhF1ASyITtF1pr8YF3_c5VYNAACpdMogJz-S5oqgjG5P9g04vm-Vhwya4Y8XI6tYp1lylO42le6fBmETmqvB8ZnvNWseFgcON-ASfSirjuaXmE5xI9YKJs1a8O8vpKzjdQxtD2SBfWJAD7r2Uy7aMaNNtuTVT1KPc=)\n",
       "\n",
       "**Web Search Queries:** ['Vertex AI managed datasets supported data types']\n",
       "\n",
       "**Search Entry Point:**\n",
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFpGUHdJaPCuIrREmSKh1vWOQ8S-CHZdKwbo-XQ-IzLYJSVLdEDF_eUS68TcrucHz5FddKGk7odw-jZ4kgHKqDomgMj0zPn479wASb8i2oaL4O4Bj-8GDEa1AHhAREHTe8MhQDSZgmOuhowaDpsDb9X-BE1lExTrv19zmmTZC8ehndlet6C9Nc_huPX8ZLUfaT3lF3VBA2WqpSo8128MtTiJl5revF6XnGngEvuQIstnZNd\">Vertex AI managed datasets supported data types</a>\n",
       "  </div>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    config=GenerateContentConfig(tools=[Tool(google_search=GoogleSearch())]),\n",
    ")\n",
    "\n",
    "display(Markdown(\"## Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT}\"))\n",
    "response = chat.send_message(PROMPT)\n",
    "print_grounding_data(response)\n",
    "\n",
    "display(Markdown(\"---\\n\"))\n",
    "\n",
    "display(Markdown(\"## Follow-up Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT_FOLLOWUP}\"))\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87be7f661f14"
   },
   "source": [
    "### Chat session grounded in Vertex AI Search results\n",
    "\n",
    "Now we can add the `tools` keyword arg with a grounding tool of `VertexAISearch` to instruct the chat session to first perform a search within your custom search app, then construct an answer based on the relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T15:40:01.475814Z",
     "iopub.status.busy": "2026-02-26T15:40:01.474049Z",
     "iopub.status.idle": "2026-02-26T15:40:01.483103Z",
     "shell.execute_reply": "2026-02-26T15:40:01.481486Z",
     "shell.execute_reply.started": "2026-02-26T15:40:01.475746Z"
    },
    "id": "8fdad0c3f1f3"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"How do I book business travel?\"\n",
    "PROMPT_FOLLOWUP = \"Give me more details.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T15:40:17.337334Z",
     "iopub.status.busy": "2026-02-26T15:40:17.335938Z",
     "iopub.status.idle": "2026-02-26T15:40:18.818699Z",
     "shell.execute_reply": "2026-02-26T15:40:18.816440Z",
     "shell.execute_reply.started": "2026-02-26T15:40:17.337269Z"
    },
    "id": "1a824202a8f0"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Prompt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> How do I book business travel?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ClientError",
     "evalue": "404 NOT_FOUND. {'error': {'code': 404, 'message': 'We were unable to find an engine to service the request. This may be an intermittent issue -- please try again in 3-5 minutes. If the issue persists, please contact support.', 'status': 'NOT_FOUND'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m display(Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     15\u001b[0m display(Markdown(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPROMPT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROMPT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m print_grounding_data(response)\n\u001b[1;32m     19\u001b[0m display(Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/chats.py:252\u001b[0m, in \u001b[0;36mChat.send_message\u001b[0;34m(self, message, config)\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    248\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage must be a valid part type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;241m.\u001b[39mPartUnion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;241m.\u001b[39mPartUnionDict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m   )\n\u001b[1;32m    251\u001b[0m input_content \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mt_content(message)\n\u001b[0;32m--> 252\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_curated_history\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_content\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m model_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    258\u001b[0m     [response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent]\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    261\u001b[0m )\n\u001b[1;32m    262\u001b[0m automatic_function_calling_history \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    263\u001b[0m     response\u001b[38;5;241m.\u001b[39mautomatic_function_calling_history\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mautomatic_function_calling_history\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    266\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/models.py:5644\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5642\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   5643\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5644\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5645\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparsed_config\u001b[49m\n\u001b[1;32m   5646\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5648\u001b[0m   function_map \u001b[38;5;241m=\u001b[39m _extra_utils\u001b[38;5;241m.\u001b[39mget_function_map(parsed_config)\n\u001b[1;32m   5649\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/models.py:4306\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4303\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[1;32m   4304\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[0;32m-> 4306\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4307\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[1;32m   4308\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m   4311\u001b[0m     config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould_return_http_response\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4312\u001b[0m ):\n\u001b[1;32m   4313\u001b[0m   return_value \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mGenerateContentResponse(sdk_http_response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/_api_client.py:1401\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m   1392\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1393\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1396\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SdkHttpResponse:\n\u001b[1;32m   1398\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m   1399\u001b[0m       http_method, path, request_dict, http_options\n\u001b[1;32m   1400\u001b[0m   )\n\u001b[0;32m-> 1401\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1402\u001b[0m   response_body \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1403\u001b[0m       response\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1404\u001b[0m   )\n\u001b[1;32m   1405\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders, body\u001b[38;5;241m=\u001b[39mresponse_body)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/_api_client.py:1237\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     retry \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretry_kwargs)\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    418\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/_api_client.py:1214\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1207\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m   1208\u001b[0m       method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   1209\u001b[0m       url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1212\u001b[0m       timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m   1213\u001b[0m   )\n\u001b[0;32m-> 1214\u001b[0m   \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1215\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m   1216\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m   1217\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/errors.py:134\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m   response_json \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mbody_segments[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/errors.py:159\u001b[0m, in \u001b[0;36mAPIError.raise_error\u001b[0;34m(cls, status_code, response_json, response)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[0;31mClientError\u001b[0m: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'We were unable to find an engine to service the request. This may be an intermittent issue -- please try again in 3-5 minutes. If the issue persists, please contact support.', 'status': 'NOT_FOUND'}}"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[\n",
    "            Tool(\n",
    "                retrieval=Retrieval(\n",
    "                    vertex_ai_search=VertexAISearch(engine=VERTEX_AI_SEARCH_ENGINE_NAME)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(\"## Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT}\"))\n",
    "response = chat.send_message(PROMPT)\n",
    "print_grounding_data(response)\n",
    "\n",
    "display(Markdown(\"---\\n\"))\n",
    "\n",
    "display(Markdown(\"## Follow-up Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT_FOLLOWUP}\"))\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro-grounding-gemini.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m139",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m139"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
